{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Block\n",
    "\n",
    "PyTorch don't have a auto padding ie padding='same' in keras. So, we have to create a auto same padding for resnet by custom class inherited from nn.Conv2d\n",
    "1. Partial from functools link:https://www.geeksforgeeks.org/partial-functions-python/. This basically pass all the argument to the corresponding function linked with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dAuto(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.padding = (self.kernel_size[0] //2, self.kernel_size[1] // 2) # Dynamic add paddding based on the kernel_size\n",
    "\n",
    "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dAuto(32, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3x3(in_channels=32, out_channels=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels #super(ResidualBlocki, self).__init__(in_channels, out_channels)\n",
    "        self.blocks = nn.Identity() # Indentity() is just like a placeholder\n",
    "        self.shortcut = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x \n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x) # Add the shortcut if inchannels!=outchannels\n",
    "        print(residual.shape)\n",
    "        x = self.blocks(x)\n",
    "        print(x.shape)\n",
    "        x += residual\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (shortcut): Identity()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResidualBlock(32, 64) # Added placeholder for block and shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "##Addition of self.shortcut \n",
    "class ResNetResidualBlock(ResidualBlock): # Note inherited from ResidualBlock \n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        \n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            'conv': nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1, stride=self.downsampling, bias=False),\n",
    "            'bn': nn.BatchNorm2d(self.expanded_channels)\n",
    "        })) if self.should_apply_shortcut else None\n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "\n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetResidualBlock(\n",
       "  (blocks): Identity()\n",
       "  (shortcut): Sequential(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNetResidualBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a basic conv2d with batch normaliztion\n",
    "\n",
    "from collections import OrderedDict\n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
    "                          'bn': nn.BatchNorm2d(out_channels) }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 224, 224])\n",
      "torch.Size([1, 64, 224, 224])\n",
      "ResNetBasicBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (conv): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Sequential(\n",
      "      (conv): Conv2dAuto(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (shortcut): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 224, 224))\n",
    "\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "block(dummy).shape\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet Layer \n",
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        # We are about to downsample directly with conv layer so stride = 2 ie downsample= 2\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels, out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels*block.expansion, out_channels, downsampling=1, *args, **kwargs) for _ in range(n-1)]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLayer(\n",
       "  (blocks): Sequential(\n",
       "    (0): ResNetBasicBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (conv): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResNetBasicBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): None\n",
       "    )\n",
       "    (2): ResNetBasicBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): ReLU()\n",
       "        (2): Sequential(\n",
       "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): None\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = torch.ones((1, 32, 48, 48))\n",
    "\n",
    "layer = ResNetLayer(64, 128, block=ResNetBasicBlock, n=3)\n",
    "# layer(dummy).shape\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet encoder composed by increasing different layers with increasing features.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,  *args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
    "    correct class by using a fully connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
    "\n",
    "def resnet34(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet50(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
    "\n",
    "def resnet101(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
    "\n",
    "def resnet152(in_channels, n_classes):\n",
    "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 256, 56, 56])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 512, 28, 28])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 1024, 14, 14])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "torch.Size([2, 2048, 7, 7])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 256, 56, 56]          16,384\n",
      "       BatchNorm2d-6          [-1, 256, 56, 56]             512\n",
      "        Conv2dAuto-7           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-8           [-1, 64, 56, 56]             128\n",
      "              ReLU-9           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-10           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
      "             ReLU-12           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "ResNetBottleNeckBlock-15          [-1, 256, 56, 56]               0\n",
      "       Conv2dAuto-16           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-22          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-23          [-1, 256, 56, 56]             512\n",
      "ResNetBottleNeckBlock-24          [-1, 256, 56, 56]               0\n",
      "       Conv2dAuto-25           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-26           [-1, 64, 56, 56]             128\n",
      "             ReLU-27           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-28           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "             ReLU-30           [-1, 64, 56, 56]               0\n",
      "       Conv2dAuto-31          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-32          [-1, 256, 56, 56]             512\n",
      "ResNetBottleNeckBlock-33          [-1, 256, 56, 56]               0\n",
      "      ResNetLayer-34          [-1, 256, 56, 56]               0\n",
      "           Conv2d-35          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-36          [-1, 512, 28, 28]           1,024\n",
      "       Conv2dAuto-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "       Conv2dAuto-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "ResNetBottleNeckBlock-45          [-1, 512, 28, 28]               0\n",
      "       Conv2dAuto-46          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "             ReLU-48          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-52          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-53          [-1, 512, 28, 28]           1,024\n",
      "ResNetBottleNeckBlock-54          [-1, 512, 28, 28]               0\n",
      "       Conv2dAuto-55          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 128, 28, 28]             256\n",
      "             ReLU-57          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-58          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "             ReLU-60          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-61          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-62          [-1, 512, 28, 28]           1,024\n",
      "ResNetBottleNeckBlock-63          [-1, 512, 28, 28]               0\n",
      "       Conv2dAuto-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "       Conv2dAuto-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "ResNetBottleNeckBlock-72          [-1, 512, 28, 28]               0\n",
      "      ResNetLayer-73          [-1, 512, 28, 28]               0\n",
      "           Conv2d-74         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-75         [-1, 1024, 14, 14]           2,048\n",
      "       Conv2dAuto-76          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-77          [-1, 256, 28, 28]             512\n",
      "             ReLU-78          [-1, 256, 28, 28]               0\n",
      "       Conv2dAuto-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-82         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-83         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-84         [-1, 1024, 14, 14]               0\n",
      "       Conv2dAuto-85          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-86          [-1, 256, 14, 14]             512\n",
      "             ReLU-87          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-88          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-89          [-1, 256, 14, 14]             512\n",
      "             ReLU-90          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-91         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-92         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-93         [-1, 1024, 14, 14]               0\n",
      "       Conv2dAuto-94          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "       Conv2dAuto-97          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-98          [-1, 256, 14, 14]             512\n",
      "             ReLU-99          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-100         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-101         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-102         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-103          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-104          [-1, 256, 14, 14]             512\n",
      "            ReLU-105          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-106          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-107          [-1, 256, 14, 14]             512\n",
      "            ReLU-108          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-109         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-110         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-111         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-112          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-113          [-1, 256, 14, 14]             512\n",
      "            ReLU-114          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-115          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-116          [-1, 256, 14, 14]             512\n",
      "            ReLU-117          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-118         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-119         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-120         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-129         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-130          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-131          [-1, 256, 14, 14]             512\n",
      "            ReLU-132          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-133          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-134          [-1, 256, 14, 14]             512\n",
      "            ReLU-135          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-136         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-137         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-138         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-139          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-140          [-1, 256, 14, 14]             512\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-142          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-143          [-1, 256, 14, 14]             512\n",
      "            ReLU-144          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-145         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-146         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-147         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-148          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-149          [-1, 256, 14, 14]             512\n",
      "            ReLU-150          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-151          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-154         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-155         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-156         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-157          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-158          [-1, 256, 14, 14]             512\n",
      "            ReLU-159          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-160          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-161          [-1, 256, 14, 14]             512\n",
      "            ReLU-162          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-163         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-164         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-165         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-166          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-167          [-1, 256, 14, 14]             512\n",
      "            ReLU-168          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-169          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-170          [-1, 256, 14, 14]             512\n",
      "            ReLU-171          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-172         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-173         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-174         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-175          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-176          [-1, 256, 14, 14]             512\n",
      "            ReLU-177          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-178          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-179          [-1, 256, 14, 14]             512\n",
      "            ReLU-180          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-181         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-182         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-183         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-184          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-187          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-188          [-1, 256, 14, 14]             512\n",
      "            ReLU-189          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-190         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-191         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-192         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-193          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-194          [-1, 256, 14, 14]             512\n",
      "            ReLU-195          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-196          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-197          [-1, 256, 14, 14]             512\n",
      "            ReLU-198          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-199         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-200         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-201         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-202          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-203          [-1, 256, 14, 14]             512\n",
      "            ReLU-204          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-205          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-206          [-1, 256, 14, 14]             512\n",
      "            ReLU-207          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-208         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-209         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-210         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-219         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-220          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 14, 14]             512\n",
      "            ReLU-222          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-223          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 14, 14]             512\n",
      "            ReLU-225          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-226         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-228         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-229          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-230          [-1, 256, 14, 14]             512\n",
      "            ReLU-231          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-232          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-233          [-1, 256, 14, 14]             512\n",
      "            ReLU-234          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-235         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-236         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-237         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-238          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-239          [-1, 256, 14, 14]             512\n",
      "            ReLU-240          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-241          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-244         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-245         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-246         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-247          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-248          [-1, 256, 14, 14]             512\n",
      "            ReLU-249          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-250          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-251          [-1, 256, 14, 14]             512\n",
      "            ReLU-252          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-253         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-254         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-255         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-256          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-257          [-1, 256, 14, 14]             512\n",
      "            ReLU-258          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-259          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-260          [-1, 256, 14, 14]             512\n",
      "            ReLU-261          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-262         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-263         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-264         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-265          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-266          [-1, 256, 14, 14]             512\n",
      "            ReLU-267          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-268          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-269          [-1, 256, 14, 14]             512\n",
      "            ReLU-270          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-271         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-272         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-273         [-1, 1024, 14, 14]               0\n",
      "      Conv2dAuto-274          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-277          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-278          [-1, 256, 14, 14]             512\n",
      "            ReLU-279          [-1, 256, 14, 14]               0\n",
      "      Conv2dAuto-280         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-281         [-1, 1024, 14, 14]           2,048\n",
      "ResNetBottleNeckBlock-282         [-1, 1024, 14, 14]               0\n",
      "     ResNetLayer-283         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-284           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-285           [-1, 2048, 7, 7]           4,096\n",
      "      Conv2dAuto-286          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-287          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-288          [-1, 512, 14, 14]               0\n",
      "      Conv2dAuto-289            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-290            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-291            [-1, 512, 7, 7]               0\n",
      "      Conv2dAuto-292           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-293           [-1, 2048, 7, 7]           4,096\n",
      "ResNetBottleNeckBlock-294           [-1, 2048, 7, 7]               0\n",
      "      Conv2dAuto-295            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-296            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-297            [-1, 512, 7, 7]               0\n",
      "      Conv2dAuto-298            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-299            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-300            [-1, 512, 7, 7]               0\n",
      "      Conv2dAuto-301           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-302           [-1, 2048, 7, 7]           4,096\n",
      "ResNetBottleNeckBlock-303           [-1, 2048, 7, 7]               0\n",
      "      Conv2dAuto-304            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-305            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-306            [-1, 512, 7, 7]               0\n",
      "      Conv2dAuto-307            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-308            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-309            [-1, 512, 7, 7]               0\n",
      "      Conv2dAuto-310           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-311           [-1, 2048, 7, 7]           4,096\n",
      "ResNetBottleNeckBlock-312           [-1, 2048, 7, 7]               0\n",
      "     ResNetLayer-313           [-1, 2048, 7, 7]               0\n",
      "   ResNetEncoder-314           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-315           [-1, 2048, 1, 1]               0\n",
      "          Linear-316                 [-1, 1000]       2,049,000\n",
      "   ResnetDecoder-317                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 44,549,160\n",
      "Trainable params: 44,549,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 373.85\n",
      "Params size (MB): 169.94\n",
      "Estimated Total Size (MB): 544.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = resnet101(3, 1000)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Alternative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "            \n",
    "        x += identity \n",
    "        x = self.relu(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu =nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet layer \n",
    "        self.layer1 = self._make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], out_channels=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*4, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x) \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                    nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
    "                    nn.BatchNorm2d(out_channels*4)\n",
    "            )\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        \n",
    "        self.in_channels = out_channels*4\n",
    "        \n",
    "        for i in range(num_residual_blocks -1):\n",
    "            layers.append(block(self.in_channels, out_channels)) \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channels=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channels, num_classes)\n",
    "\n",
    "def ResNet101(img_channels=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 4, 23, 3], img_channels, num_classes)\n",
    "\n",
    "def ResNet152(img_channels=3, num_classes=1000):\n",
    "    return ResNet(block, [3, 8, 36, 3], img_channels, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,160\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,640\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "             ReLU-13          [-1, 256, 56, 56]               0\n",
      "           Conv2d-14          [-1, 256, 56, 56]          16,640\n",
      "      BatchNorm2d-15          [-1, 256, 56, 56]             512\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "            block-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18           [-1, 64, 56, 56]          16,448\n",
      "      BatchNorm2d-19           [-1, 64, 56, 56]             128\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24          [-1, 256, 56, 56]          16,640\n",
      "      BatchNorm2d-25          [-1, 256, 56, 56]             512\n",
      "             ReLU-26          [-1, 256, 56, 56]               0\n",
      "             ReLU-27          [-1, 256, 56, 56]               0\n",
      "            block-28          [-1, 256, 56, 56]               0\n",
      "           Conv2d-29           [-1, 64, 56, 56]          16,448\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "           Conv2d-32           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-33           [-1, 64, 56, 56]             128\n",
      "             ReLU-34           [-1, 64, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 56, 56]          16,640\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "             ReLU-37          [-1, 256, 56, 56]               0\n",
      "             ReLU-38          [-1, 256, 56, 56]               0\n",
      "            block-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]          32,896\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          66,048\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,584\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "            block-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,664\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          66,048\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "             ReLU-62          [-1, 512, 28, 28]               0\n",
      "            block-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,664\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          66,048\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "             ReLU-73          [-1, 512, 28, 28]               0\n",
      "            block-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,664\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          66,048\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "             ReLU-84          [-1, 512, 28, 28]               0\n",
      "            block-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         131,328\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "           Conv2d-92         [-1, 1024, 14, 14]         263,168\n",
      "      BatchNorm2d-93         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95         [-1, 1024, 14, 14]         525,312\n",
      "      BatchNorm2d-96         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-97         [-1, 1024, 14, 14]               0\n",
      "            block-98         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         262,400\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102          [-1, 256, 14, 14]         590,080\n",
      "     BatchNorm2d-103          [-1, 256, 14, 14]             512\n",
      "            ReLU-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105         [-1, 1024, 14, 14]         263,168\n",
      "     BatchNorm2d-106         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-107         [-1, 1024, 14, 14]               0\n",
      "            ReLU-108         [-1, 1024, 14, 14]               0\n",
      "           block-109         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]         262,400\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "            ReLU-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113          [-1, 256, 14, 14]         590,080\n",
      "     BatchNorm2d-114          [-1, 256, 14, 14]             512\n",
      "            ReLU-115          [-1, 256, 14, 14]               0\n",
      "          Conv2d-116         [-1, 1024, 14, 14]         263,168\n",
      "     BatchNorm2d-117         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-118         [-1, 1024, 14, 14]               0\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "           block-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,400\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         590,080\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         263,168\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "            ReLU-130         [-1, 1024, 14, 14]               0\n",
      "           block-131         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-132          [-1, 256, 14, 14]         262,400\n",
      "     BatchNorm2d-133          [-1, 256, 14, 14]             512\n",
      "            ReLU-134          [-1, 256, 14, 14]               0\n",
      "          Conv2d-135          [-1, 256, 14, 14]         590,080\n",
      "     BatchNorm2d-136          [-1, 256, 14, 14]             512\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138         [-1, 1024, 14, 14]         263,168\n",
      "     BatchNorm2d-139         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-140         [-1, 1024, 14, 14]               0\n",
      "            ReLU-141         [-1, 1024, 14, 14]               0\n",
      "           block-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,400\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         590,080\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         263,168\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "            ReLU-152         [-1, 1024, 14, 14]               0\n",
      "           block-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 512, 14, 14]         524,800\n",
      "     BatchNorm2d-155          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-156          [-1, 512, 14, 14]               0\n",
      "          Conv2d-157            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-158            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-159            [-1, 512, 7, 7]               0\n",
      "          Conv2d-160           [-1, 2048, 7, 7]       1,050,624\n",
      "     BatchNorm2d-161           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163           [-1, 2048, 7, 7]       2,099,200\n",
      "     BatchNorm2d-164           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-165           [-1, 2048, 7, 7]               0\n",
      "           block-166           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-167            [-1, 512, 7, 7]       1,049,088\n",
      "     BatchNorm2d-168            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-169            [-1, 512, 7, 7]               0\n",
      "          Conv2d-170            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-172            [-1, 512, 7, 7]               0\n",
      "          Conv2d-173           [-1, 2048, 7, 7]       1,050,624\n",
      "     BatchNorm2d-174           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-175           [-1, 2048, 7, 7]               0\n",
      "            ReLU-176           [-1, 2048, 7, 7]               0\n",
      "           block-177           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-178            [-1, 512, 7, 7]       1,049,088\n",
      "     BatchNorm2d-179            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-180            [-1, 512, 7, 7]               0\n",
      "          Conv2d-181            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-182            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-183            [-1, 512, 7, 7]               0\n",
      "          Conv2d-184           [-1, 2048, 7, 7]       1,050,624\n",
      "     BatchNorm2d-185           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-186           [-1, 2048, 7, 7]               0\n",
      "            ReLU-187           [-1, 2048, 7, 7]               0\n",
      "           block-188           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-189           [-1, 2048, 1, 1]               0\n",
      "          Linear-190                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,583,592\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 328.67\n",
      "Params size (MB): 97.59\n",
      "Estimated Total Size (MB): 426.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res50 = ResNet50()\n",
    "summary(res50, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
